{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3jM2vsZnR9Y",
        "outputId": "8fbe3b89-20b8-4101-e9cd-3e797a96caa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun 23 10:24:55 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P0             44W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B3leg6NoXm0",
        "outputId": "75b16821-8ae8-484b-8763-6a65d17e00af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone  https://github.com/WongKinYiu/yolov9.git\n",
        "%cd yolov9\n",
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_yIkRCKoaqV",
        "outputId": "a96e3694-e968-4e03-9b4b-66e6b01a07f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov9'...\n",
            "remote: Enumerating objects: 781, done.\u001b[K\n",
            "remote: Counting objects: 100% (316/316), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 781 (delta 265), reused 256 (delta 256), pack-reused 465 (from 1)\u001b[K\n",
            "Receiving objects: 100% (781/781), 3.25 MiB | 16.81 MiB/s, done.\n",
            "Resolving deltas: 100% (339/339), done.\n",
            "/content/yolov9\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q roboflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyIaW5RppAqe",
        "outputId": "45ec8cc1-dcfe-43e7-92e4-e7169e73e668"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-e.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-s.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-m.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-c.pt\n",
        "!wget -P {HOME}/weights -q https://github.com/WongKinYiu/yolov9/releases/download/v0.1/gelan-e.pt"
      ],
      "metadata": {
        "id": "nZ372qpspRt1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la {HOME}/weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t9iBJP8p8Ty",
        "outputId": "930f0da3-4725-4105-cb51-04e37f16cee6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 487304\n",
            "drwxr-xr-x 2 root root      4096 Jun 23 10:26 .\n",
            "drwxr-xr-x 1 root root      4096 Jun 23 10:26 ..\n",
            "-rw-r--r-- 1 root root  51508261 Feb 18  2024 gelan-c.pt\n",
            "-rw-r--r-- 1 root root 117203713 Feb 18  2024 gelan-e.pt\n",
            "-rw-r--r-- 1 root root 103153312 Feb 18  2024 yolov9-c.pt\n",
            "-rw-r--r-- 1 root root 140217688 Feb 18  2024 yolov9-e.pt\n",
            "-rw-r--r-- 1 root root  66462416 Jun  1  2024 yolov9-m.pt\n",
            "-rw-r--r-- 1 root root  20423912 Jun  5  2024 yolov9-s.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kmsg09eqCvM",
        "outputId": "d3e6aa32-39af-447d-e11c-41679931e932"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow==9.5.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "b8C8n53Vua80",
        "outputId": "e054734c-4bd3-4df5-e68e-8927cd9b4b7b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==9.5.0\n",
            "  Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pillow-heif 0.22.0 requires pillow>=10.1.0, but you have pillow 9.5.0 which is incompatible.\n",
            "scikit-image 0.25.2 requires pillow>=10.1, but you have pillow 9.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "3f22c7d8db844b8194cdf93a2a8abb8d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Tt4s8S2wXTb",
        "outputId": "5c16a79d-74e1-4788-d206-d3b0ffbd296d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.5.1\n",
            "  Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision==0.20.1\n",
            "  Downloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio==2.5.1\n",
            "  Downloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Collecting triton==3.1.0 (from torch==2.5.1)\n",
            "  Downloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1) (9.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1) (3.0.2)\n",
            "Downloading torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.20.1-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.5.1-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed torch-2.5.1 torchaudio-2.5.1 torchvision-0.20.1 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPC31xTXu3q2",
        "outputId": "00459cb1-594c-4226-d96e-6068004da741"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import roboflow\n",
        "from google.colab import userdata\n",
        "\n",
        "# Assuming your API key secret is named 'ROBOFLOW_API_KEY'\n",
        "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n",
        "\n",
        "rf = roboflow.Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "\n",
        "project = rf.workspace(\"roboflow-jvuqo\").project(\"football-players-detection-3zvbc\")\n",
        "version = project.version(8)\n",
        "dataset = version.download(\"yolov9\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WLGYKi-qzaL",
        "outputId": "75c9a579-2055-4fed-b641-0933563259b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in football-players-detection-8 to yolov9:: 100%|██████████| 57648/57648 [00:00<00:00, 78599.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to football-players-detection-8 in yolov9:: 100%|██████████| 522/522 [00:00<00:00, 3330.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{dataset.location}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLnRoWDzvcOx",
        "outputId": "b1983229-86c1-49b5-e5bc-9d8a1d71725e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'/content/football-players-detection-8'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: data.yaml에 path: /content/football-players-detection-8/data.yaml 삽입하기\n",
        "\n",
        "# Insert 'path: /content/football-players-detection-8/data.yaml' into data.yaml\n",
        "data_yaml_path = f\"{dataset.location}/data.yaml\"\n",
        "\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "with open(data_yaml_path, 'w') as f:\n",
        "    for line in lines:\n",
        "        f.write(line)\n",
        "    # Check if the path is already there to avoid duplicates\n",
        "    if 'path: /content/football-players-detection-8/data.yaml' not in lines:\n",
        "        f.write('path: /content/football-players-detection-8/data.yaml\\n')\n",
        "\n",
        "print(f\"Inserted path into {data_yaml_path}\")\n",
        "!cat {data_yaml_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VnnhdBayowk",
        "outputId": "93a1a18d-82a3-44fb-dde0-08fca5d84b60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted path into /content/football-players-detection-8/data.yaml\n",
            "names:\n",
            "- ball\n",
            "- goalkeeper\n",
            "- player\n",
            "- referee\n",
            "nc: 4\n",
            "roboflow:\n",
            "  license: CC BY 4.0\n",
            "  project: football-players-detection-3zvbc\n",
            "  url: https://universe.roboflow.com/roboflow-jvuqo/football-players-detection-3zvbc/dataset/8\n",
            "  version: 8\n",
            "  workspace: roboflow-jvuqo\n",
            "test: ../test/images\n",
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "path: /content/football-players-detection-8/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/yolov9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCmBsoIov-rC",
        "outputId": "dd70944c-495e-4c69-f2aa-6cf48d595609"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "--batch 16 --epochs 25 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n",
        "--data {dataset.location}/data.yaml \\\n",
        "--weights {HOME}/weights/gelan-c.pt \\\n",
        "--cfg models/detect/gelan-c.yaml \\\n",
        "--hyp hyp.scratch-high.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAjAjzyUunLT",
        "outputId": "9e56b179-671e-4438-8b31-4df22f5b65de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-23 08:03:56.808197: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750665836.830280   10372 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750665836.836784   10372 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-23 08:03:56.860195: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/weights/gelan-c.pt, cfg=models/detect/gelan-c.yaml, data=/content/football-players-detection-8/data.yaml, hyp=hyp.scratch-high.yaml, epochs=25, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.13 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "/content/yolov9/train.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(weights, map_location='cpu')  # load checkpoint to CPU to avoid CUDA memory leak\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
            "  3                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            "  4                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
            "  5                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  6                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  7                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  8                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  9                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n",
            " 10                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 11           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 12                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n",
            " 16                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            " 17          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 18                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n",
            " 19                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            " 20           [-1, 9]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 22      [15, 18, 21]  1   5493724  models.yolo.DDetect                     [4, [256, 512, 512]]          \n",
            "gelan-c summary: 621 layers, 25440156 parameters, 25440140 gradients, 103.2 GFLOPs\n",
            "\n",
            "Transferred 931/937 items from /content/weights/gelan-c.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/football-players-detection-8/train/labels.cache... 204 images, 0 backgrounds, 0 corrupt: 100% 204/204 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/football-players-detection-8/valid/labels.cache... 38 images, 0 backgrounds, 0 corrupt: 100% 38/38 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/train/exp5/labels.jpg... \n",
            "/content/yolov9/train.py:244: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp5\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/13 [00:00<?, ?it/s]/content/yolov9/train.py:302: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/24      11.8G      1.578       5.06     0.9568        654        640:   8% 1/13 [00:12<02:27, 12.32s/it]/content/yolov9/train.py:302: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/24      13.2G      1.464      4.023     0.9191        632        640: 100% 13/13 [00:30<00:00,  2.31s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.24it/s]\n",
            "                   all         38        905       0.94      0.224      0.212      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/24      13.2G      1.335      1.289     0.8461        553        640: 100% 13/13 [00:12<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.95it/s]\n",
            "                   all         38        905      0.959      0.228      0.242       0.17\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/24      13.2G      1.265      1.088     0.8459        508        640: 100% 13/13 [00:12<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.04it/s]\n",
            "                   all         38        905       0.52      0.285      0.259     0.0978\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/24      13.2G       1.46      1.006     0.8444        517        640: 100% 13/13 [00:12<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.00it/s]\n",
            "                   all         38        905      0.603      0.359      0.341      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/24      13.2G      1.377      1.148     0.8373        477        640: 100% 13/13 [00:12<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.93it/s]\n",
            "                   all         38        905      0.644      0.404      0.383      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/24        15G      1.483      1.109     0.8447        450        640: 100% 13/13 [00:13<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.03it/s]\n",
            "                   all         38        905      0.715      0.446      0.487      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/24        15G       1.64      1.032      0.865        570        640: 100% 13/13 [00:12<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.99it/s]\n",
            "                   all         38        905      0.677      0.432      0.447      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/24        15G      1.631      1.022     0.8552        604        640: 100% 13/13 [00:12<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.04it/s]\n",
            "                   all         38        905      0.669      0.453      0.457      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/24        15G      1.678      1.058     0.8536        537        640: 100% 13/13 [00:13<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.04it/s]\n",
            "                   all         38        905      0.848      0.479      0.552      0.236\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/24        15G       1.56      1.027      0.855        671        640: 100% 13/13 [00:12<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.03it/s]\n",
            "                   all         38        905      0.847      0.477       0.58      0.272\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/24        15G      1.449     0.8145     0.8467        259        640: 100% 13/13 [00:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.00it/s]\n",
            "                   all         38        905      0.853       0.52      0.597      0.361\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/24        15G      1.339      0.758     0.8452        235        640: 100% 13/13 [00:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.92it/s]\n",
            "                   all         38        905      0.885      0.535      0.608      0.335\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/24        15G      1.232     0.6733     0.8404        259        640: 100% 13/13 [00:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.01it/s]\n",
            "                   all         38        905      0.864      0.536      0.634      0.363\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/24        15G      1.212     0.6987     0.8294        224        640: 100% 13/13 [00:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.98it/s]\n",
            "                   all         38        905      0.666      0.553      0.642      0.396\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/24        15G      1.104     0.6001     0.8291        270        640: 100% 13/13 [00:11<00:00,  1.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.99it/s]\n",
            "                   all         38        905      0.768      0.609      0.674      0.387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/24        15G      1.095     0.5775     0.8244        235        640: 100% 13/13 [00:11<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.04it/s]\n",
            "                   all         38        905      0.804      0.635       0.69      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/24        15G      1.101      0.579     0.8209        207        640: 100% 13/13 [00:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.92it/s]\n",
            "                   all         38        905      0.812      0.605      0.673      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/24        15G      1.056     0.5347     0.8217        273        640: 100% 13/13 [00:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.00it/s]\n",
            "                   all         38        905      0.833      0.591      0.687      0.408\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/24        15G      1.037     0.5307     0.8211        232        640: 100% 13/13 [00:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.92it/s]\n",
            "                   all         38        905      0.847      0.623        0.7       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/24        15G     0.9636     0.5028     0.8107        233        640: 100% 13/13 [00:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.00it/s]\n",
            "                   all         38        905      0.871      0.614      0.719      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/24        15G     0.9714     0.5048     0.8149        261        640: 100% 13/13 [00:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.99it/s]\n",
            "                   all         38        905       0.85      0.634      0.715       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/24        15G     0.9102     0.4741     0.8039        252        640: 100% 13/13 [00:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.98it/s]\n",
            "                   all         38        905      0.848      0.637      0.725      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/24        15G     0.8804      0.453     0.8076        246        640: 100% 13/13 [00:11<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.89it/s]\n",
            "                   all         38        905      0.867      0.644       0.73      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/24        15G     0.8789     0.4515     0.8049        258        640: 100% 13/13 [00:11<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.98it/s]\n",
            "                   all         38        905      0.867      0.665      0.733      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/24        15G      0.857     0.4451     0.8003        253        640: 100% 13/13 [00:11<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.99it/s]\n",
            "                   all         38        905      0.859      0.658      0.737       0.49\n",
            "\n",
            "25 epochs completed in 0.105 hours.\n",
            "/content/yolov9/utils/general.py:999: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  x = torch.load(f, map_location=torch.device('cpu'))\n",
            "Optimizer stripped from runs/train/exp5/weights/last.pt, saved as runs/train/exp5/weights/last_striped.pt, 51.4MB\n",
            "Optimizer stripped from runs/train/exp5/weights/best.pt, saved as runs/train/exp5/weights/best_striped.pt, 51.4MB\n",
            "\n",
            "Validating runs/train/exp5/weights/best.pt...\n",
            "/content/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25230172 parameters, 0 gradients, 101.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  2.37it/s]\n",
            "                   all         38        905      0.858      0.658      0.739       0.49\n",
            "                  ball         38         35      0.842      0.153      0.279     0.0834\n",
            "            goalkeeper         38         27          1      0.813       0.93      0.652\n",
            "                player         38        754      0.935      0.934      0.968       0.73\n",
            "               referee         38         89      0.657      0.731      0.778      0.496\n",
            "Results saved to \u001b[1mruns/train/exp5\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/WongKinYiu/yolov9/issues/420\n",
        "\n",
        " train_dual.py 을 사용 해야 한다.\n",
        "\n",
        " 다만 컴퓨팅 리소스를 높게 요구한다.\n",
        "\n",
        "train.py는 오로지 gelang만 쓴다"
      ],
      "metadata": {
        "id": "K0B-Wn_l07m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_dual.py \\\n",
        "--batch 16 --epochs 25 --img 640 --device 0 --min-items 0 --close-mosaic 15 \\\n",
        "--data {dataset.location}/data.yaml \\\n",
        "--weights {HOME}/weights/yolov9-m.pt \\\n",
        "--cfg models/detect/yolov9-m.yaml \\\n",
        "--hyp hyp.scratch-high.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93V8GqU906PJ",
        "outputId": "3458fcca-6f2a-4b39-c1d5-fcde194baaaf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-23 10:28:15.347482: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-23 10:28:15.364421: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750674495.385892    2304 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750674495.392280    2304 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-23 10:28:15.413529: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain_dual: \u001b[0mweights=/content/weights/yolov9-m.pt, cfg=models/detect/yolov9-m.yaml, data=/content/football-players-detection-8/data.yaml, hyp=hyp.scratch-high.yaml, epochs=25, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "YOLO 🚀 v0.1-104-g5b1ea9a Python-3.11.13 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 14.3MB/s]\n",
            "/content/yolov9/train_dual.py:110: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(weights, map_location='cpu')  # load checkpoint to CPU to avoid CUDA memory leak\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1         0  models.common.Silence                   []                            \n",
            "  1                -1  1       928  models.common.Conv                      [3, 32, 3, 2]                 \n",
            "  2                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  3                -1  1    171648  models.common.RepNCSPELAN4              [64, 128, 128, 64, 1]         \n",
            "  4                -1  1    276960  models.common.AConv                     [128, 240]                    \n",
            "  5                -1  1    629520  models.common.RepNCSPELAN4              [240, 240, 240, 120, 1]       \n",
            "  6                -1  1    778320  models.common.AConv                     [240, 360]                    \n",
            "  7                -1  1   1414080  models.common.RepNCSPELAN4              [360, 360, 360, 180, 1]       \n",
            "  8                -1  1   1556160  models.common.AConv                     [360, 480]                    \n",
            "  9                -1  1   2511840  models.common.RepNCSPELAN4              [480, 480, 480, 240, 1]       \n",
            " 10                -1  1    577440  models.common.SPPELAN                   [480, 480, 240]               \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 7]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1   1586880  models.common.RepNCSPELAN4              [840, 360, 360, 180, 1]       \n",
            " 14                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 15           [-1, 5]  1         0  models.common.Concat                    [1]                           \n",
            " 16                -1  1    715920  models.common.RepNCSPELAN4              [600, 240, 240, 120, 1]       \n",
            " 17                -1  1    397808  models.common.AConv                     [240, 184]                    \n",
            " 18          [-1, 13]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1480320  models.common.RepNCSPELAN4              [544, 360, 360, 180, 1]       \n",
            " 20                -1  1    778080  models.common.AConv                     [360, 240]                    \n",
            " 21          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 22                -1  1   2627040  models.common.RepNCSPELAN4              [720, 480, 480, 240, 1]       \n",
            " 23                 5  1     57840  models.common.CBLinear                  [240, [240]]                  \n",
            " 24                 7  1    216600  models.common.CBLinear                  [360, [240, 360]]             \n",
            " 25                 9  1    519480  models.common.CBLinear                  [480, [240, 360, 480]]        \n",
            " 26                 0  1       928  models.common.Conv                      [3, 32, 3, 2]                 \n",
            " 27                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            " 28                -1  1    171648  models.common.RepNCSPELAN4              [64, 128, 128, 64, 1]         \n",
            " 29                -1  1    276960  models.common.AConv                     [128, 240]                    \n",
            " 30  [23, 24, 25, -1]  1         0  models.common.CBFuse                    [[0, 0, 0]]                   \n",
            " 31                -1  1    629520  models.common.RepNCSPELAN4              [240, 240, 240, 120, 1]       \n",
            " 32                -1  1    778320  models.common.AConv                     [240, 360]                    \n",
            " 33      [24, 25, -1]  1         0  models.common.CBFuse                    [[1, 1]]                      \n",
            " 34                -1  1   1414080  models.common.RepNCSPELAN4              [360, 360, 360, 180, 1]       \n",
            " 35                -1  1   1556160  models.common.AConv                     [360, 480]                    \n",
            " 36          [25, -1]  1         0  models.common.CBFuse                    [[2]]                         \n",
            " 37                -1  1   2511840  models.common.RepNCSPELAN4              [480, 480, 480, 240, 1]       \n",
            " 38[31, 34, 37, 16, 19, 22]  1   9095096  models.yolo.DualDDetect                 [4, [240, 360, 480, 240, 360, 480]]\n",
            "yolov9-m summary: 938 layers, 32768536 parameters, 32768504 gradients, 132.4 GFLOPs\n",
            "\n",
            "Transferred 1400/1412 items from /content/weights/yolov9-m.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 230 weight(decay=0.0), 247 weight(decay=0.0005), 245 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0m1 validation error for InitSchema\n",
            "size\n",
            "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...: None, 'strict': False}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/football-players-detection-8/train/labels... 204 images, 0 backgrounds, 0 corrupt: 100% 204/204 [00:00<00:00, 5932.66it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/football-players-detection-8/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/football-players-detection-8/valid/labels... 38 images, 0 backgrounds, 0 corrupt: 100% 38/38 [00:00<00:00, 2424.45it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/football-players-detection-8/valid/labels.cache\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "/content/yolov9/train_dual.py:255: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0% 0/13 [00:00<?, ?it/s]/content/yolov9/train_dual.py:313: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/24      14.8G      1.997      5.178      1.204        654        640:   0% 0/13 [00:02<?, ?it/s]WARNING ⚠️ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions\n",
            "       0/24      14.8G      1.997      5.178      1.204        654        640:   8% 1/13 [00:08<01:46,  8.91s/it]/content/yolov9/train_dual.py:313: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(amp):\n",
            "       0/24      19.1G      1.913      4.564      1.174        632        640: 100% 13/13 [00:20<00:00,  1.58s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:01<00:00,  1.36it/s]\n",
            "                   all         38        905      0.694      0.221      0.221      0.149\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/24      19.1G      1.694      1.697      1.076        553        640: 100% 13/13 [00:05<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.01it/s]\n",
            "                   all         38        905      0.699      0.241      0.226      0.118\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/24      19.1G      1.608      1.319       1.06        508        640: 100% 13/13 [00:05<00:00,  2.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.35it/s]\n",
            "                   all         38        905      0.561      0.308      0.287       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/24      19.1G      1.809      1.337      1.061        517        640: 100% 13/13 [00:05<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.82it/s]\n",
            "                   all         38        905      0.634      0.386      0.358      0.226\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/24      19.1G      1.809      1.364      1.058        477        640: 100% 13/13 [00:05<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.81it/s]\n",
            "                   all         38        905      0.716      0.396      0.413      0.239\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/24      20.9G      1.872      1.268      1.065        450        640: 100% 13/13 [00:05<00:00,  2.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.23it/s]\n",
            "                   all         38        905      0.722      0.457      0.475      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/24      20.9G      2.162      1.318      1.086        570        640: 100% 13/13 [00:05<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.14it/s]\n",
            "                   all         38        905      0.675      0.429      0.452      0.203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/24      20.9G      2.082      1.364      1.061        604        640: 100% 13/13 [00:05<00:00,  2.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.20it/s]\n",
            "                   all         38        905      0.733      0.458      0.496      0.266\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/24      20.9G      1.957      1.324      1.065        537        640: 100% 13/13 [00:05<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.31it/s]\n",
            "                   all         38        905      0.665      0.401      0.416      0.141\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/24      20.9G      1.998      1.308      1.064        671        640: 100% 13/13 [00:05<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.04it/s]\n",
            "                   all         38        905      0.864      0.541      0.604      0.339\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/24      20.9G      1.782      1.047       1.06        259        640: 100% 13/13 [00:04<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.15it/s]\n",
            "                   all         38        905      0.828      0.519      0.615      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/24      20.9G      1.618      1.019      1.038        235        640: 100% 13/13 [00:04<00:00,  2.90it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.28it/s]\n",
            "                   all         38        905      0.826      0.479      0.599      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/24      20.9G      1.591     0.9245      1.053        259        640: 100% 13/13 [00:04<00:00,  3.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.07it/s]\n",
            "                   all         38        905      0.857      0.607      0.635      0.376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/24      20.9G      1.566     0.8643      1.034        224        640: 100% 13/13 [00:04<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.20it/s]\n",
            "                   all         38        905      0.744      0.544      0.593      0.296\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/24      20.9G      1.457     0.7971      1.036        270        640: 100% 13/13 [00:04<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.11it/s]\n",
            "                   all         38        905      0.896      0.571      0.656      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/24      20.9G      1.324     0.7937      1.029        235        640: 100% 13/13 [00:04<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.02it/s]\n",
            "                   all         38        905      0.849      0.587      0.656      0.402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/24      20.9G      1.427     0.7588      1.026        207        640: 100% 13/13 [00:04<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.90it/s]\n",
            "                   all         38        905      0.883      0.596      0.687      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/24      20.9G      1.344     0.7132      1.024        273        640: 100% 13/13 [00:04<00:00,  3.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.15it/s]\n",
            "                   all         38        905        0.8       0.62      0.686      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/24      20.9G      1.334     0.7014      1.027        232        640: 100% 13/13 [00:04<00:00,  2.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  4.94it/s]\n",
            "                   all         38        905       0.81      0.648      0.701      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/24      20.9G      1.242     0.6637      1.017        233        640: 100% 13/13 [00:04<00:00,  2.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.23it/s]\n",
            "                   all         38        905      0.767      0.599      0.678      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/24      20.9G      1.207     0.6549      1.018        261        640: 100% 13/13 [00:04<00:00,  3.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.07it/s]\n",
            "                   all         38        905      0.915       0.62      0.733      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/24      20.9G      1.181     0.6355      1.006        252        640: 100% 13/13 [00:04<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.05it/s]\n",
            "                   all         38        905      0.878      0.637       0.71      0.461\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/24      20.9G      1.125     0.5982      1.009        246        640: 100% 13/13 [00:04<00:00,  2.92it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.14it/s]\n",
            "                   all         38        905      0.925      0.656      0.728      0.471\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/24      20.9G      1.133     0.6004      1.008        258        640: 100% 13/13 [00:04<00:00,  2.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.18it/s]\n",
            "                   all         38        905      0.943      0.663      0.736      0.475\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/24      20.9G      1.096     0.5883      1.003        253        640: 100% 13/13 [00:04<00:00,  2.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  5.08it/s]\n",
            "                   all         38        905      0.937      0.664      0.741      0.477\n",
            "\n",
            "25 epochs completed in 0.057 hours.\n",
            "/content/yolov9/utils/general.py:999: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  x = torch.load(f, map_location=torch.device('cpu'))\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 66.3MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 66.3MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "/content/yolov9/models/experimental.py:243: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "Fusing layers... \n",
            "yolov9-m summary: 588 layers, 32557504 parameters, 0 gradients, 130.7 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 2/2 [00:00<00:00,  3.50it/s]\n",
            "                   all         38        905      0.936      0.664      0.741      0.477\n",
            "                  ball         38         35          1      0.142      0.277     0.0704\n",
            "            goalkeeper         38         27      0.915      0.926      0.948      0.644\n",
            "                player         38        754      0.935      0.923      0.968      0.694\n",
            "               referee         38         89      0.894      0.666       0.77      0.502\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# After training, the experiment results are typically saved in the `runs/train/exp` directory\n",
        "# in the yolov9 repository directory.\n",
        "# You might need to adjust the source path based on the actual output of your training runs.\n",
        "source_exp_path = f\"{HOME}/yolov9/runs/train/exp\"\n",
        "destination_drive_path = \"/content/drive/MyDrive/yolov9_training_exp\"\n",
        "\n",
        "# Copy the experiment directory to Google Drive\n",
        "# The -r flag is for recursive copying of the directory contents\n",
        "!cp -r {source_exp_path} {destination_drive_path}\n",
        "\n",
        "print(f\"Copied experiment results from {source_exp_path} to {destination_drive_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEeU005VXnxC",
        "outputId": "04ab8a48-bb7d-4995-fbe0-1c319057b077"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Copied experiment results from /content/yolov9/runs/train/exp to /content/drive/MyDrive/yolov9_training_exp\n"
          ]
        }
      ]
    }
  ]
}